{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘experiments’: File exists\n",
      "mkdir: cannot create directory ‘pretrained’: File exists\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sunghoonYoon/XAI_CAMs \"xai\"\n",
    "\n",
    "%cd xai\n",
    "\n",
    "!mkdir experiments\n",
    "\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import tools.utils as utils\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mxnet-cu112\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start experiment xai!\n",
      "./experiments/xai already exsits.\n",
      "---------------------------------------------------- SETUP ----------------------------------------------------\n",
      "train_list : train_aug\n",
      "val_list : train\n",
      "num_workers : 8\n",
      "batch_size : 8\n",
      "resize : [256, 448]\n",
      "crop : 384\n",
      "lr : 0.01\n",
      "wt_dec : 0.0005\n",
      "max_epochs : 15\n",
      "name : xai\n",
      "model : model_xai\n",
      "seed : 4242\n",
      "vis : False\n",
      "dict : False\n",
      "crf : False\n",
      "print_freq : 10\n",
      "alphas : [6, 10, 24]\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------- start train loop --------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Epoch 000 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1322 [00:43<31:59,  1.46s/it]  -\n",
      "  1%|          | 11/1322 [00:44<28:54,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bce : 0.47098\n",
      "acc_bce : 22.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1322 [00:54<22:22,  1.03s/it]-\n",
      "  2%|▏         | 21/1322 [00:55<22:51,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bce : 0.12963\n",
      "acc_bce : 31.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 30/1322 [01:04<23:05,  1.07s/it]-\n",
      "  2%|▏         | 31/1322 [01:05<22:32,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bce : 0.09481\n",
      "acc_bce : 26.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 40/1322 [01:15<21:56,  1.03s/it]-\n",
      "  3%|▎         | 41/1322 [01:16<22:20,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bce : 0.06236\n",
      "acc_bce : 35.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 41/1322 [01:16<40:05,  1.88s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/shyoon3/colab/main.ipynb 셀 2\u001b[0m in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.50.181/mnt/shyoon3/colab/main.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39miter\u001b[39m, pack \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(train_data_loader)):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.50.181/mnt/shyoon3/colab/main.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m     model\u001b[39m.\u001b[39munpack(pack)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B143.248.50.181/mnt/shyoon3/colab/main.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m     model\u001b[39m.\u001b[39;49mupdate(epo)            \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.50.181/mnt/shyoon3/colab/main.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39miter\u001b[39m\u001b[39m%\u001b[39margs\u001b[39m.\u001b[39mprint_freq\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39miter\u001b[39m\u001b[39m!=\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.50.181/mnt/shyoon3/colab/main.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m         model\u001b[39m.\u001b[39mprint_log(epo, \u001b[39miter\u001b[39m\u001b[39m/\u001b[39mtrain_num_batch, logger)\n",
      "File \u001b[0;32m/mnt/shyoon3/colab/models/model_xai.py:137\u001b[0m, in \u001b[0;36mmodel_WSSS.update\u001b[0;34m(self, epo)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate\u001b[39m(\u001b[39mself\u001b[39m, epo):\n\u001b[1;32m    136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt_er\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcam_er, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_er \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet_er(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimg)\n\u001b[1;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_bce \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbce(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_er, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_all)\n\u001b[1;32m    141\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_bce\n",
      "File \u001b[0;32m~/anaconda3/envs/wsss_ksj/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/anaconda3/envs/wsss_ksj/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:166\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    165\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule(\u001b[39m*\u001b[39minputs[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 166\u001b[0m replicas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplicate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_ids[:\u001b[39mlen\u001b[39;49m(inputs)])\n\u001b[1;32m    167\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel_apply(replicas, inputs, kwargs)\n\u001b[1;32m    168\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgather(outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/wsss_ksj/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:171\u001b[0m, in \u001b[0;36mDataParallel.replicate\u001b[0;34m(self, module, device_ids)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreplicate\u001b[39m(\u001b[39mself\u001b[39m, module, device_ids):\n\u001b[0;32m--> 171\u001b[0m     \u001b[39mreturn\u001b[39;00m replicate(module, device_ids, \u001b[39mnot\u001b[39;49;00m torch\u001b[39m.\u001b[39;49mis_grad_enabled())\n",
      "File \u001b[0;32m~/anaconda3/envs/wsss_ksj/lib/python3.8/site-packages/torch/nn/parallel/replicate.py:91\u001b[0m, in \u001b[0;36mreplicate\u001b[0;34m(network, devices, detach)\u001b[0m\n\u001b[1;32m     89\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(network\u001b[39m.\u001b[39mparameters())\n\u001b[1;32m     90\u001b[0m param_indices \u001b[39m=\u001b[39m {param: idx \u001b[39mfor\u001b[39;00m idx, param \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(params)}\n\u001b[0;32m---> 91\u001b[0m param_copies \u001b[39m=\u001b[39m _broadcast_coalesced_reshape(params, devices, detach)\n\u001b[1;32m     93\u001b[0m buffers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(network\u001b[39m.\u001b[39mbuffers())\n\u001b[1;32m     94\u001b[0m buffers_rg \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/wsss_ksj/lib/python3.8/site-packages/torch/nn/parallel/replicate.py:71\u001b[0m, in \u001b[0;36m_broadcast_coalesced_reshape\u001b[0;34m(tensors, devices, detach)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[39m# Use the autograd function to broadcast if not detach\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(tensors) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 71\u001b[0m         tensor_copies \u001b[39m=\u001b[39m Broadcast\u001b[39m.\u001b[39;49mapply(devices, \u001b[39m*\u001b[39;49mtensors)\n\u001b[1;32m     72\u001b[0m         \u001b[39mreturn\u001b[39;00m [tensor_copies[i:i \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(tensors)]\n\u001b[1;32m     73\u001b[0m                 \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tensor_copies), \u001b[39mlen\u001b[39m(tensors))]\n\u001b[1;32m     74\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/wsss_ksj/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:23\u001b[0m, in \u001b[0;36mBroadcast.forward\u001b[0;34m(ctx, target_gpus, *inputs)\u001b[0m\n\u001b[1;32m     21\u001b[0m ctx\u001b[39m.\u001b[39mnum_inputs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(inputs)\n\u001b[1;32m     22\u001b[0m ctx\u001b[39m.\u001b[39minput_device \u001b[39m=\u001b[39m inputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_device()\n\u001b[0;32m---> 23\u001b[0m outputs \u001b[39m=\u001b[39m comm\u001b[39m.\u001b[39;49mbroadcast_coalesced(inputs, ctx\u001b[39m.\u001b[39;49mtarget_gpus)\n\u001b[1;32m     24\u001b[0m non_differentiables \u001b[39m=\u001b[39m []\n\u001b[1;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m idx, input_requires_grad \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(ctx\u001b[39m.\u001b[39mneeds_input_grad[\u001b[39m1\u001b[39m:]):\n",
      "File \u001b[0;32m~/anaconda3/envs/wsss_ksj/lib/python3.8/site-packages/torch/nn/parallel/comm.py:58\u001b[0m, in \u001b[0;36mbroadcast_coalesced\u001b[0;34m(tensors, devices, buffer_size)\u001b[0m\n\u001b[1;32m     56\u001b[0m devices \u001b[39m=\u001b[39m [_get_device_index(d) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m devices]\n\u001b[1;32m     57\u001b[0m tensors \u001b[39m=\u001b[39m [_handle_complex(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tensors]\n\u001b[0;32m---> 58\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_broadcast_coalesced(tensors, devices, buffer_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "categories = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', \n",
    "            'bus', 'car', 'cat', 'chair', 'cow', \n",
    "            'diningtable', 'dog', 'horse', 'motorbike', 'person', \n",
    "            'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Dataset\n",
    "parser.add_argument(\"--train_list\", default=\"train\", type=str)\n",
    "parser.add_argument(\"--val_list\", default=\"train\", type=str)\n",
    "parser.add_argument(\"--num_workers\", default=8, type=int)\n",
    "parser.add_argument(\"--batch_size\", default=8, type=int)\n",
    "parser.add_argument(\"--resize\", default=[256,448], nargs='+', type=int)\n",
    "parser.add_argument(\"--crop\", default=384, type=int)\n",
    "\n",
    "# Learning rate\n",
    "parser.add_argument(\"--lr\", default=0.01, type=float)\n",
    "parser.add_argument(\"--wt_dec\", default=5e-4, type=float)  \n",
    "parser.add_argument(\"--max_epochs\", default=15, type=int)\n",
    "parser.add_argument(\"--name\", default='xai', type=str)\n",
    "\n",
    "# Experiments\n",
    "parser.add_argument(\"--model\", default='model_xai', type=str) # model_cse\n",
    "parser.add_argument(\"--seed\", default=4242, type=int)\n",
    "\n",
    "\n",
    "# Output\n",
    "parser.add_argument(\"--vis\", action='store_true')\n",
    "parser.add_argument(\"--dict\", action='store_true')\n",
    "parser.add_argument(\"--crf\", action='store_true')\n",
    "parser.add_argument(\"--print_freq\", default=10, type=int)\n",
    "parser.add_argument(\"--alphas\", default=[6,10,24], nargs='+', type=int)    \n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "print('Start experiment ' + args.name + '!')\n",
    "exp_path, ckpt_path, train_path, val_path, infer_path, dict_path, crf_path, log_path = utils.make_path(args)\n",
    "\n",
    "if osp.isfile(log_path):\n",
    "        os.remove(log_path)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "console_handler = logging.StreamHandler()\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "file_handler = logging.FileHandler(log_path)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "print('-'*52 + ' SETUP ' + '-'*52)\n",
    "for arg in vars(args):\n",
    "    print(arg + ' : ' + str(getattr(args, arg)))\n",
    "print('-'*111)\n",
    "\n",
    "train_dataset = utils.build_dataset(phase='train', path='voc12/'+args.train_list+'.txt', resize=args.resize, crop=args.crop)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)\n",
    "\n",
    "train_num_img = len(train_dataset)\n",
    "train_num_batch = len(train_data_loader)\n",
    "\n",
    "max_step = train_num_img // args.batch_size * args.max_epochs\n",
    "args.max_step = max_step\n",
    "\n",
    "model = getattr(importlib.import_module('models.'+args.model), 'model_WSSS')(args)\n",
    "model.train_setup()\n",
    "\n",
    "print('-'*111)\n",
    "print(('-'*43)+' start train loop '+('-'*44))\n",
    "max_epo = 0\n",
    "max_miou = 0\n",
    "max_thres = 0\n",
    "max_list = []\n",
    "\n",
    "for epo in range(args.max_epochs):   \n",
    "    \n",
    "    # Train\n",
    "    print('-'*111)\n",
    "    print('Epoch ' + str(epo).zfill(3) + ' train')\n",
    "    model.set_phase('train')\n",
    "    for iter, pack in enumerate(tqdm(train_data_loader)):\n",
    "        model.unpack(pack)\n",
    "        model.update(epo)            \n",
    "        if iter%args.print_freq==0 and iter!=0:\n",
    "            model.print_log(epo, iter/train_num_batch, logger)\n",
    "            logger.info('-')           \n",
    "    model.save_model(epo, ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('wsss_ksj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f0c8f0cdee1354878dc5d710d6113d8ed82e602ef56b0871a36b2b2c0d87e6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
